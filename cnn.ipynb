{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from layer import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Dense, reLU, Sigmoid, Reshape,Conv, Tanh, load_data, Layer\n",
    "from losses import mse, mse_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data(1500, flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padding(Layer):\n",
    "    def __init__(self, input_shape, num_pads):\n",
    "        self.num_pads = num_pads\n",
    "        self.input_shape = input_shape\n",
    "        self.num_channels = input_shape[0]\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.padded_x= np.zeros((x.shape[0],x.shape[1]+2*self.num_pads,x.shape[2]+2*self.num_pads))\n",
    "        for i in range(self.num_channels):\n",
    "            self.padded_x[i] = np.pad(x[i], (self.num_pads,self.num_pads), 'constant',constant_values=(0,0))\n",
    "            \n",
    "        return self.padded_x\n",
    "        \n",
    "    def backward(self, grad,lr):\n",
    "        return grad[: , self.num_pads:-self.num_pads, self.num_pads:-self.num_pads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, input):\n",
    "    output = input\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(network, input):\n",
    "    outputs=np.zeros((input.shape[0], network[-2].w.shape[1]))\n",
    "    for index,x in enumerate(input):\n",
    "        outputs[index] = predict(network, x)\n",
    "        \n",
    "    return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
    "    for e in range(epochs):\n",
    "        error = 0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "\n",
    "            output = predict(network, x)\n",
    "\n",
    "            # error\n",
    "            error += loss(y, output)\n",
    "\n",
    "            # backward\n",
    "            grad = loss_prime(y, output)\n",
    "            for layer in reversed(network):\n",
    "                grad = layer.backward(grad, learning_rate)\n",
    "            \n",
    "        \n",
    "        error /= len(x_train)\n",
    "        if verbose:\n",
    "            print(f\"{e + 1}/{epochs}, error={error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, input):\n",
    "        tmp = np.exp(input)\n",
    "        self.output = tmp / np.sum(tmp)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # This version is faster than the one presented in the video\n",
    "        n = np.size(self.output)\n",
    "        \n",
    "        return np.dot( (np.identity(n) - self.output.T) * self.output,output_gradient.T).T\n",
    "        # Original formula:\n",
    "        # tmp = np.tile(self.output, n)\n",
    "        # return np.dot(tmp * (np.identity(n) - np.transpose(tmp)), output_gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=[\n",
    "    Padding((1,28,28),1),\n",
    "    Conv((1,30,30), 3, 3),\n",
    "    reLU(),\n",
    "    Reshape((3,1,28,28), 3*28*28),\n",
    "    Dense(3*28*28, 60,0.1),\n",
    "    reLU(),\n",
    "    Dense(60, 2,0.1),\n",
    "    Sigmoid()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100, error=0.4988960017972826\n",
      "2/100, error=0.1455365803856948\n",
      "3/100, error=0.010397802753522374\n",
      "4/100, error=0.008858056215392273\n",
      "5/100, error=0.007961468767282506\n",
      "6/100, error=0.0073359857223030435\n",
      "7/100, error=0.006863491544110227\n",
      "8/100, error=0.00649186250489715\n",
      "9/100, error=0.006187682029084591\n",
      "10/100, error=0.005933134316048035\n",
      "11/100, error=0.005714922424882422\n",
      "12/100, error=0.005526070272722492\n",
      "13/100, error=0.005359171565936962\n",
      "14/100, error=0.00521136129243648\n",
      "15/100, error=0.005079038086412111\n",
      "16/100, error=0.004958970034512359\n",
      "17/100, error=0.0048493507915675195\n",
      "18/100, error=0.004748780572255683\n",
      "19/100, error=0.0046561528950783805\n",
      "20/100, error=0.0045714017002102215\n",
      "21/100, error=0.004492291935129788\n",
      "22/100, error=0.004418494983520312\n",
      "23/100, error=0.004349240404031756\n",
      "24/100, error=0.004284531521062284\n",
      "25/100, error=0.004224752122125378\n",
      "26/100, error=0.004167062446576176\n",
      "27/100, error=0.004112759079906638\n",
      "28/100, error=0.004061113557372091\n",
      "29/100, error=0.004012517991774641\n",
      "30/100, error=0.00396581314876177\n",
      "31/100, error=0.003921971070061115\n",
      "32/100, error=0.0038793808898958584\n",
      "33/100, error=0.0038388639362140604\n",
      "34/100, error=0.0037999451541424942\n",
      "35/100, error=0.003762600847107224\n",
      "36/100, error=0.0037264172048438386\n",
      "37/100, error=0.003691904816713401\n",
      "38/100, error=0.003658530547444537\n",
      "39/100, error=0.0036262439542297893\n",
      "40/100, error=0.003595378679220782\n",
      "41/100, error=0.003565587342882816\n",
      "42/100, error=0.003537069111444691\n",
      "43/100, error=0.0035090108122259717\n",
      "44/100, error=0.003482123579111626\n",
      "45/100, error=0.0034557535841118867\n",
      "46/100, error=0.003430513051464584\n",
      "47/100, error=0.0034059185833319604\n",
      "48/100, error=0.0033821394662903875\n",
      "49/100, error=0.0033591524283186204\n",
      "50/100, error=0.0033362325105339963\n",
      "51/100, error=0.003314430953122861\n",
      "52/100, error=0.0032935787584233954\n",
      "53/100, error=0.003273058512002315\n",
      "54/100, error=0.0032529522718554712\n",
      "55/100, error=0.003232818771136659\n",
      "56/100, error=0.0032142635549155863\n",
      "57/100, error=0.0031951153970640462\n",
      "58/100, error=0.0031771679744976612\n",
      "59/100, error=0.00315964750108802\n",
      "60/100, error=0.0031422184171027703\n",
      "61/100, error=0.003124816916753402\n",
      "62/100, error=0.0031083190197477802\n",
      "63/100, error=0.003092259033177766\n",
      "64/100, error=0.003076567593725162\n",
      "65/100, error=0.003061480846420932\n",
      "66/100, error=0.003046022986415742\n",
      "67/100, error=0.003031426728154883\n",
      "68/100, error=0.0030171798420430703\n",
      "69/100, error=0.0030026503227927664\n",
      "70/100, error=0.0029889046927281926\n",
      "71/100, error=0.0029750989808199537\n",
      "72/100, error=0.002962055656651127\n",
      "73/100, error=0.0029482854619290637\n",
      "74/100, error=0.002936913403834201\n",
      "75/100, error=0.002926344164724819\n",
      "76/100, error=0.0029145554674987403\n",
      "77/100, error=0.0029028610993132244\n",
      "78/100, error=0.0028920025923825352\n",
      "79/100, error=0.002879948533767888\n",
      "80/100, error=0.002867987455797218\n",
      "81/100, error=0.0028564559198281957\n",
      "82/100, error=0.0028454864528648064\n",
      "83/100, error=0.002834170483167024\n",
      "84/100, error=0.0028232275250894756\n",
      "85/100, error=0.0028123179636887342\n",
      "86/100, error=0.0028016838248829264\n",
      "87/100, error=0.0027910961439122175\n",
      "88/100, error=0.002779572279929833\n",
      "89/100, error=0.002769855711588451\n",
      "90/100, error=0.002759230841107682\n",
      "91/100, error=0.002749116960287416\n",
      "92/100, error=0.002744871494722505\n",
      "93/100, error=0.002732822493925388\n",
      "94/100, error=0.0027238052454568967\n",
      "95/100, error=0.0027157564618441768\n",
      "96/100, error=0.002705684821682062\n",
      "97/100, error=0.0026993038959870663\n",
      "98/100, error=0.0026888918037604632\n",
      "99/100, error=0.0026830903089860958\n",
      "100/100, error=0.0026744104055619407\n"
     ]
    }
   ],
   "source": [
    "train(network, mse, mse_prime, x_train, y_train, epochs = 100, learning_rate = 0.01, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predict_test_set(network, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993333333333333\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, y_test):\n",
    "    return np.mean(predictions == y_test)\n",
    "\n",
    "print(accuracy(predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
